<!--
Title: "Fouille de donn√©es massives : Th√©or√®mes"
Author: rsquaredata
Last updated: 2025-12-09
-->

# Fouilles de donn√©es massives (SVM & Noyaux) - Th√©or√®mes

---

##  Th√©or√®me de la marge maximale

**√ânonc√© :**  
La solution optimale d‚Äôun SVM lin√©aire correspond √† l‚Äôhyperplan qui maximise la marge s√©parant les deux classes :

$$
\gamma = \frac{2}{\|w\|}
$$

Sous contrainte :
$$
y_i(\langle w, x_i \rangle + b) \ge 1
$$

**Intuition :**  
Maximiser la marge = choisir le s√©parateur le plus robuste aux erreurs de classification.  
Plus la marge est grande, plus la g√©n√©ralisation est forte (moins de variance).

**Cons√©quence :**  
Le probl√®me d‚Äôoptimisation du SVM devient :

$$
\min_{w,b} \frac{1}{2}\|w\|^2 \quad \text{sous } y_i(\langle w, x_i \rangle + b) \ge 1
$$

---

## Dualit√© forte (Primal vs Dual)

**√ânonc√© :**  
Sous des hypoth√®ses de convexit√©, le **probl√®me dual** du SVM admet **la m√™me solution** que le **probl√®me primal**.

$$
\min_{w,b,\xi} L_{\text{primal}}(w,b,\xi)
\quad \Longleftrightarrow \quad
\max_{\alpha} L_{\text{dual}}(\alpha)
$$

**Cons√©quences :**
- Le probl√®me dual est strictement concave ‚Üí **solution unique.**  
- On peut retrouver $w$ et $b$ √† partir des variables duales $(\alpha_i)$ (via les **conditions KKT**).  
- En pratique, on pr√©f√®re souvent r√©soudre le dual (moins co√ªteux quand $m \lt$).

**Rappel des liens primal/dual :** $w = \sum_i \alpha_i y_i x_i, \quad \sum_i \alpha_i y_i = 0$

---

## Conditions de Karush-Kuhn-Tucker (KKT)

**√ânonc√© :**  
Les conditions KKT d√©finissent le lien entre les variables primales $(w, b, x_i)$ et duales $(\alpha, \beta)$ :

$$
\begin{cases}
\frac{\partial L}{\partial w} = 0 \Rightarrow w = \sum_i \alpha_i y_i x_i \\
\frac{\partial L}{\partial b} = 0 \Rightarrow \sum_i \alpha_i y_i = 0 \\
\frac{\partial L}{\partial x_i} = 0 \Rightarrow \alpha_i + \beta_i = \frac{C}{m}
\end{cases}
$$

**Interpr√©tation :**
- Ces √©quations assurent que la solution trouv√©e est **stationnaire** (point-selle du Lagrangien).  
- Elles permettent de reconstruire le mod√®le primal √† partir du dual.

---

## Th√©or√®me de Mercer (1909)

**√ânonc√© :**  
Soit $X \subset \mathbb{R}^d$ un compact et $K : X \times X \to \mathbb{R}$ une forme bilin√©aire sym√©trique **semi-d√©finie positive (PSD)**.  
Alors il existe :
- une base orthogonale $(\Phi_j)_{j \in \mathbb{N}}$
- une suite $(\lambda_j)_{j \in \mathbb{N}}$, avec $\lambda_j \ge 0*

telles que :

$$
K(x, x') = \sum_{j=1}^\infty \lambda_j \Phi_j(x)\Phi_j(x') = \langle \Phi(x), \Phi(x') \rangle
$$

**Cons√©quence :**  
‚Üí Toute fonction noyau valide correspond implicitement √† un produit scalaire dans un **espace de Hilbert** (feature space).

**En pratique :**

$$
k(x, x') = \langle \phi(x), \phi(x') \rangle
$$

sans jamais calculer explicitement $\phi$ ‚Äî c‚Äôest **l‚Äôastuce du noyau.**

---

## Bochner (1930) *(li√© √† Mercer, pour RFF)*

**√ânonc√© simplifi√© :**  
Une fonction $k(x, x')** continue et √† valeurs r√©elles est un **noyau positif** (PSD) *si et seulement si* c‚Äôest la **transform√©e de Fourier** d‚Äôune mesure positive.

$$
k(x, x') = \int_{\mathbb{R}^d} e^{i\omega^T(x - x')} p(\omega)\, d\omega
$$

**Application pratique :**  
‚Üí Fondement des **Random Fourier Features (Rahimi & Recht, 2007)**, qui approximent le noyau par projections al√©atoires :

$$
k(x, x') \approx \frac{1}{R}\sum_{r=1}^R \cos(\omega_r^T x + b_r)\cos(\omega_r^\top x' + b_r)
$$

---

## Gram matrix & unicit√©

**√ânonc√© :**
Dans le dual du SVM :

$$
G_{ij} = y_i y_j \langle x_i, x_j \rangle
$$

La matrice de Gram $G$ est **semi-d√©finie positive**, donc le probl√®me dual est **strictement concave** ‚Üí **solution unique.**

---

## üí° intuitions √† retenir

| Concept | Id√©e-cl√© |
|----------|-----------|
| **Produit scalaire** | Mesure de similarit√© entre deux vecteurs. Dans un espace transform√© (noyau), il devient une similarit√© implicite. |
| **Matrice PSD** | Matrice $A$ telle que $x^\top A x \ge 0$ pour tout $x$. Garantit la convexit√© et l‚Äôexistence d‚Äôun minimum global. |
| **Dualit√© forte** | Primal et dual ont la m√™me valeur optimale - pratique pour r√©soudre les grands probl√®mes. |
| **KKT** | Conditions reliant contraintes et optimum : indispensables pour reconstruire $w, b$. |
| **Mercer** | Garantit que le noyau correspond √† un vrai produit scalaire dans un espace de plus grande dimension. |
| **Bochner** | Lie les noyaux positifs √† la transform√©e de Fourier - base des approximations al√©atoires (RFF). |

---

## R√©f√©rences cours

- Metzler, G. *Fouille de Donn√©es Massives ‚Äî SVM et Noyaux* (slides 2022-2024)  
- Rahimi, A. & Recht, B. (2007). *Random Features for Large-Scale Kernel Machines.*  
- Mercer, J. (1909). *Functions of Positive and Negative Type.*  
- Vapnik, V. (1995). *The Nature of Statistical Learning Theory.*
