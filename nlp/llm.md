<!--
title: "LLM"
author: rsquatedata
last updates: 2025-12-09
-->

<!--

séance 1 (20251204 am)

sources :
- Jurafsky
- Decoder-only Transformers, cgatgpts specific transformers -> youtube
- maartengrootendorst -> a visual guide to quantization
- en gros tous les liens dans le PDF de la séance

papier d'OpenAI sorti en 2025 : "Why language Models Hallucinate" (spoiler : parce qu'il préfère halluciner que dire qu'il ne sait pas ; parce que les gens préfèrenet une réponse plutôt que pas de réponse)

Mistral Large sorti y a une semaine

grosse différence entre la recherche théorique et la réalisation industrielle de la mise en production

LLM = un algo parmi d'autres, IA c'est pas que LLM ; un LLM n'est qu'un perroquet stochastique

antropomorphisme -> réflexe à casser en entreprise

attention à la bulle LLM, perspective : sécurité des données -> y penser pour le projet (comment mettre en prod un truc qui prévient les failles de sécurité)

Le Cun -> hiérarchie d'information, réfléchir par concepts et non par mots

offres : on voit du "full stack avec connaissance IA", moins de data scientists

candidatures : OpenAI, Mistral, HuggingFace

---

Séance 2

- chunks
- projet : on va choisir un modèle et Clovis veut qu'on dise pourquoi (meilleurs scores ? local ? ouvert ? etc.)

---

Séance 3

- tips : utiliser uv (environnements), ONNX (partager des modèles)
- tip : pour tester Ollama en local, le dockeriser (isolation & easy cleanup)
- en TD : faire un modèle de ML qui protège contre les failles de sécurité

spoiler projet : former des groupes (quatre groupes de 5 et un groupe de 4), 3 sujets







-->
